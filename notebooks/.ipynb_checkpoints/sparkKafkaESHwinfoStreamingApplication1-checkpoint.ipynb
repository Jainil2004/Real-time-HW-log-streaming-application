{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfacddb-2a2a-4186-8e39-44d7fa41d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark + kafka + ES streaming application 1\n",
    "# goal: connect spark, kafka and ES and transfer logs\n",
    "# kafka - data streaming from HWinfo\n",
    "# spark - process data coming from kafka\n",
    "# ES - store the processed logs for future retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ee0f53-4690-4983-a707-ed5527454969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, DoubleType, StringType, IntegerType, StructField\n",
    "from pyspark.sql.functions import col, split, trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a4bf59-6d9c-4a61-bfba-aea6901b4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaToElasticsearchHwinfoLogs\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.2,org.elasticsearch:elasticsearch-spark-30_2.12:8.10.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805fde49-7a35-40d5-b669-efdaaadb93f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://84cc2f90a1b3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>KafkaToElasticsearchHwinfoLogs</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3d38354850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542c0102-6cb6-4bbd-8a17-25fe7d55d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kafka = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"hwinfo\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "742506e8-0ac7-4244-946e-f39d03e8bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwinfo_schema = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"Core_Clocks_avg_MHz\", IntegerType(), True),\n",
    "    StructField(\"Bus_Clock_MHz\", DoubleType(), True),\n",
    "    StructField(\"Core_Usage_avg_percent\", DoubleType(), True),\n",
    "    StructField(\"Core_Temperatures_avg_C\", DoubleType(), True),\n",
    "    StructField(\"CPU_Package_C\", IntegerType(), True),\n",
    "    StructField(\"CPU_Package_Power_W\", DoubleType(), True),\n",
    "])\n",
    "# hwinfo_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bae65c5-2821-4dd4-a47f-9390acb1f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the binary shit show to what the it should actually represent\n",
    "json_data = df_kafka.selectExpr(\"CAST(value AS STRING)\").alias(\"strings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558c3c5-8cc7-4989-93eb-e2f265986753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "# Convert Kafka value from bytes to string\n",
    "df_parsed = json_data.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "# Split CSV data into individual fields based on your schema\n",
    "# df_final = df_parsed.select(\n",
    "#     split(col(\"value\"), \",\")[0].alias(\"Date\"),\n",
    "#     split(col(\"value\"), \",\")[1].alias(\"Time\"),\n",
    "#     split(col(\"value\"), \",\")[2].alias(\"Core_Clocks_avg_MHz\"),\n",
    "#     split(col(\"value\"), \",\")[3].alias(\"Ring_LLC_Clock_MHz\"),\n",
    "#     split(col(\"value\"), \",\")[4].alias(\"Core_Usage_avg_percent\"),\n",
    "#     split(col(\"value\"), \",\")[5].alias(\"Core_Temperatures_avg_C\"),\n",
    "#     split(col(\"value\"), \",\")[6].alias(\"CPU_Package_C\"),\n",
    "#     split(col(\"value\"), \",\")[7].alias(\"CPU_Package_Power_W\"),\n",
    "# )\n",
    "# .cast(\"float\")\n",
    "# df_final = df_parsed.select(\n",
    "#     split(col(\"value\"), \",\")[0].alias(\"Date\"),\n",
    "#     split(col(\"value\"), \",\")[1].alias(\"Time\"),\n",
    "#     trim(split(col(\"value\"), \",\")[2]).cast(\"Float\").alias(\"Core_Clocks_avg_MHz\"),\n",
    "#     trim(split(col(\"value\"), \",\")[3]).cast(\"Float\").alias(\"Ring_LLC_Clock_MHz\"),\n",
    "#     trim(split(col(\"value\"), \",\")[4]).cast(\"Float\").alias(\"Core_Usage_avg_percent\"),\n",
    "#     trim(split(col(\"value\"), \",\")[5]).cast(\"Float\").alias(\"Core_Temperatures_avg_C\"),\n",
    "#     trim(split(col(\"value\"), \",\")[6]).cast(\"Float\").alias(\"CPU_Package_C\"),\n",
    "#     trim(split(col(\"value\"), \",\")[7]).cast(\"Float\").alias(\"CPU_Package_Power_W\"),\n",
    "# )\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df_final = df_parsed.withColumn(\"value\", regexp_replace(col(\"value\"), \"[\\\\[\\\\]']\", \"\")) \n",
    "df_final = df_final.select(\n",
    "    split(col(\"value\"), \",\")[0].alias(\"Date\"),\n",
    "    split(col(\"value\"), \",\")[1].alias(\"Time\"),\n",
    "    split(col(\"value\"), \",\")[2].cast(\"FLOAT\").alias(\"Core_Clocks_avg_MHz\"),\n",
    "    split(col(\"value\"), \",\")[3].cast(\"FLOAT\").alias(\"Ring_LLC_Clock_MHz\"),\n",
    "    split(col(\"value\"), \",\")[4].cast(\"FLOAT\").alias(\"Core_Usage_avg_percent\"),\n",
    "    split(col(\"value\"), \",\")[5].cast(\"FLOAT\").alias(\"Core_Temperatures_avg_C\"),\n",
    "    split(col(\"value\"), \",\")[6].cast(\"FLOAT\").alias(\"CPU_Package_C\"),\n",
    "    split(col(\"value\"), \",\")[7].cast(\"FLOAT\").alias(\"CPU_Package_Power_W\")\n",
    ")\n",
    "\n",
    "\n",
    "# df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da755b-757e-4ad9-98ee-1c8155ad408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_query = df_final.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"org.elasticsearch.spark.sql\") \\\n",
    "    .option(\"es.nodes\", \"elasticsearch\") \\\n",
    "    .option(\"es.port\", \"9200\") \\\n",
    "    .option(\"es.resource\", \"hwinfo\") \\\n",
    "    .option(\"es.net.ssl\", \"false\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/spark-checkpoints\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea651d9-012f-45b8-b4b3-4171411d86bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.writeStream \\\n",
    "#     .format(\"org.elasticsearch.spark.sql\") \\\n",
    "#     .option(\"es.nodes\", \"elasticsearch\") \\\n",
    "#     .option(\"es.port\", \"9200\") \\\n",
    "#     .option(\"es.resource\", \"hwinfo\") \\\n",
    "#     .option(\"es.net.ssl\", \"false\") \\\n",
    "#     .option(\"checkpointLocation\", \"/tmp/spark-checkpoints\") \\\n",
    "#     .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5aa35d1-45ac-48d9-b356-75893f56b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = df_final.writeStream.outputMode(\"append\").format(\"console\").start()\n",
    "# query = df_parsed.writeStream.outputMode(\"append\").format(\"console\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430bf599-fcd0-48e9-9853-4d248bdbb169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
